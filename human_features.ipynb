{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XDG_CACHE_HOME=/mnt/ssd-1/caleb/hf_cache\n"
     ]
    }
   ],
   "source": [
    "%env XDG_CACHE_HOME=/mnt/ssd-1/caleb/hf_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "from delphi.autoencoders import load_eai_autoencoders\n",
    "\n",
    "from delphi.features import FeatureDataset\n",
    "from delphi.config import ExperimentConfig, FeatureConfig\n",
    "from delphi.features.constructors import default_constructor\n",
    "from delphi.features.samplers import sample\n",
    "from functools import partial\n",
    "from clearnets.train.sparse_gptneox import SparseGPTNeoXForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from nnsight import NNsight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import HTML, display\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colorbar(min_value, max_value, white = 255, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    # Add color bar\n",
    "    colorbar = \"\"\n",
    "    num_colors = 4\n",
    "    if(min_value < -negative_threshold):\n",
    "        for i in range(num_colors, 0, -1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((min_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1); color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    # Do zero\n",
    "    colorbar += f'<span style=\"background-color:rgba({white},{white},{white},1);color:rgb(0,0,0)\">&nbsp0.0&nbsp</span>'\n",
    "    # Do positive\n",
    "    if(max_value > positive_threshold):\n",
    "        for i in range(1, num_colors+1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((max_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1);color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    return colorbar\n",
    "\n",
    "def value_to_color(activation, max_value, min_value, white = 255, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    if activation > positive_threshold:\n",
    "        ratio = activation/max_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1)'\n",
    "    elif activation < -negative_threshold:\n",
    "        ratio = activation/min_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1)'\n",
    "    else:\n",
    "        text_color = \"0,0,0\"\n",
    "        background_color = f'rgba({white},{white},{white},1)'\n",
    "    return text_color, background_color\n",
    "\n",
    "def convert_token_array_to_list(array):\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        if array.dim() == 1:\n",
    "            array = [array.tolist()]\n",
    "        elif array.dim()==2:\n",
    "            array = array.tolist()\n",
    "        else: \n",
    "            raise NotImplementedError(\"tokens must be 1 or 2 dimensional\")\n",
    "    elif isinstance(array, list):\n",
    "        # ensure it's a list of lists\n",
    "        if isinstance(array[0], int):\n",
    "            array = [array]\n",
    "    return array\n",
    "\n",
    "def tokens_and_activations_to_html(toks, activations, tokenizer, logit_diffs=None, model_type=\"causal\"):\n",
    "    # text_spacing = \"0.07em\"\n",
    "    text_spacing = \"0.00em\"\n",
    "    toks = convert_token_array_to_list(toks)\n",
    "    activations = convert_token_array_to_list(activations)\n",
    "    # toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '↵') for t in tok] for tok in toks]\n",
    "    toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '\\\\n') for t in tok] for tok in toks]\n",
    "    highlighted_text = []\n",
    "    # Make background black\n",
    "    # highlighted_text.append('<body style=\"background-color:black; color: white;\">')\n",
    "    highlighted_text.append(\"\"\"\n",
    "<body style=\"background-color: black; color: white;\">\n",
    "\"\"\")\n",
    "    max_value = max([max(activ) for activ in activations])\n",
    "    min_value = min([min(activ) for activ in activations])\n",
    "    if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "        logit_max_value = max([max(activ) for activ in logit_diffs])\n",
    "        logit_min_value = min([min(activ) for activ in logit_diffs])\n",
    "\n",
    "    # Add color bar\n",
    "    highlighted_text.append(\"Token Activations: \" + make_colorbar(min_value, max_value))\n",
    "    if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.1em;\"></div>')\n",
    "        highlighted_text.append(\"Logit Diff: \" + make_colorbar(logit_min_value, logit_max_value))\n",
    "    \n",
    "    highlighted_text.append('<div style=\"margin-top: 0.5em;\"></div>')\n",
    "    for seq_ind, (act, tok) in enumerate(zip(activations, toks)):\n",
    "        for act_ind, (a, t) in enumerate(zip(act, tok)):\n",
    "            if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "                highlighted_text.append('<div style=\"display: inline-block;\">')\n",
    "            text_color, background_color = value_to_color(a, max_value, min_value)\n",
    "            highlighted_text.append(f'<span style=\"background-color:{background_color};margin-right: {text_spacing}; color:rgb({text_color})\">{t.replace(\" \", \"&nbsp\").replace(\"<bos>\",\"BOS\")}</span>')\n",
    "            if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "                logit_diffs_act = logit_diffs[seq_ind][act_ind]\n",
    "                _, logit_background_color = value_to_color(logit_diffs_act, logit_max_value, logit_min_value)\n",
    "                highlighted_text.append(f'<div style=\"display: block; margin-right: {text_spacing}; height: 10px; background-color:{logit_background_color}; text-align: center;\"></div></div>')\n",
    "        if(logit_diffs is not None and model_type==\"reward_model\"):\n",
    "            reward_change = logit_diffs[seq_ind].item()\n",
    "            text_color, background_color = value_to_color(reward_change, 10, -10)\n",
    "            highlighted_text.append(f'<br><span>Reward: </span><span style=\"background-color:{background_color};margin-right: {text_spacing}; color:rgb({text_color})\">{reward_change:.2f}</span>')\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.2em;\"></div>')\n",
    "        # highlighted_text.append('<br><br>')\n",
    "    # highlighted_text.append('</body>')\n",
    "    highlighted_text = ''.join(highlighted_text)\n",
    "    return highlighted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def load_examples(layer_name=None,latent_number=None):\n",
    "    \n",
    "    feature_cfg = FeatureConfig(width=16384)\n",
    "    \n",
    "    experiment_cfg = ExperimentConfig(n_random=5,train_type=\"quantiles\",n_examples_train=40,n_quantiles=5,example_ctx_len=32)\n",
    "\n",
    "    module = f\".gpt_neox.layers.{layer_name}.mlp\"\n",
    "    dataset = FeatureDataset(\n",
    "        raw_dir=\"/mnt/ssd-1/caleb/clearnets/Dense-FineWebEduDedup-58M-s=42/cached_activations/sparse\",\n",
    "        cfg=feature_cfg,\n",
    "        modules=[module],\n",
    "        features={module:torch.tensor([latent_number])},\n",
    "        tokenizer=AutoTokenizer.from_pretrained(\"EleutherAI/FineWeb-restricted\"),\n",
    "    )\n",
    "    constructor=partial(\n",
    "                default_constructor,\n",
    "                # tokens=dataset.tokens,\n",
    "                token_loader=None,\n",
    "                n_random=experiment_cfg.n_random, \n",
    "                ctx_len=32, \n",
    "                max_examples=10000\n",
    "            )\n",
    "    sampler=partial(sample,cfg=experiment_cfg)\n",
    "    loader = partial(dataset.load,constructor=constructor,sampler=sampler)\n",
    "\n",
    "    all_examples = {}\n",
    "    maximum_activations = {}\n",
    "    for records in loader(False):\n",
    "        for record in records:\n",
    "            train_examples = record.train\n",
    "            all_examples[str(record.feature)] = train_examples\n",
    "            all_examples[str(record.feature)].extend(record.random_examples)\n",
    "            maximum_activations[str(record.feature)] = record.max_activation\n",
    "\n",
    "    return all_examples, maximum_activations\n",
    "\n",
    "def plot_examples(layer_name=None,latent_number=None):\n",
    "    all_examples, maximum_activations = load_examples(layer_name,latent_number)\n",
    "    keys = list(all_examples.keys())\n",
    "    \n",
    "    current_index = [0]  # Use a list to store the current index so it can be modified in the callback\n",
    "    explanations = {}  # Dictionary to store explanations\n",
    "\n",
    "    def display_example(index):\n",
    "        key = keys[index]\n",
    "        print(key)\n",
    "        list_tokens = []\n",
    "        list_activations = []\n",
    "        for example in all_examples[key]:\n",
    "            example_tokens = example.tokens\n",
    "            activations = example.activations/maximum_activations[key]\n",
    "            list_tokens.append(example_tokens)\n",
    "            list_activations.append(activations.tolist())\n",
    "\n",
    "        display(HTML(tokens_and_activations_to_html(list_tokens, list_activations, tokenizer)))\n",
    "\n",
    "    def on_submit(b):\n",
    "        key = keys[current_index[0]]\n",
    "        explanations[key] = text_box.value\n",
    "        current_index[0] = (current_index[0] + 1) % len(keys)\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "        display_example(current_index[0])\n",
    "    \n",
    "    def on_skip(b):\n",
    "        current_index[0] = (current_index[0] + 1) % len(keys)\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "        display_example(current_index[0])\n",
    "        \n",
    "    def on_save(b):\n",
    "        with open(f\"{layer_name}_explanations.json\", \"w\") as f:\n",
    "            json.dump(explanations, f)\n",
    "        print(f\"Explanations saved to {layer_name}_explanations.json\")\n",
    "\n",
    "    text_box = widgets.Text(description=\"Explanation:\")\n",
    "    submit_button = widgets.Button(description=\"Submit\")\n",
    "    submit_button.on_click(on_submit)\n",
    "    skip_button = widgets.Button(description=\"Skip\")\n",
    "    skip_button.on_click(on_skip)\n",
    "    save_button = widgets.Button(description=\"Save\")\n",
    "    save_button.on_click(on_save)\n",
    "    display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "    display_example(current_index[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SparseGPTNeoXForCausalLM(\"\", device_map=\"cpu\", dispatch=True,torch_dtype=\"float16\")\n",
    "# model = SparseGPTNeoXForCausalLM.from_pretrained(\n",
    "#     \"/mnt/ssd-1/caleb/clearnets/Dense-FineWebEduDedup-58M-s=42/sparse-checkpoint-164000\",\n",
    "#     device_map=\"cuda\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/FineWeb-restricted\")\n",
    "model = SparseGPTNeoXForCausalLM.from_pretrained(\n",
    "    \"/mnt/ssd-1/caleb/clearnets/Dense-FineWebEduDedup-58M-s=42/sparse-checkpoint-164000\",\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "\n",
    "model = NNsight(model, device_map=\"auto\", torch_dtype=torch.bfloat16, tokenizer=tokenizer)\n",
    "model.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading .gpt_neox.layers.0.mlp: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading .gpt_neox.layers.0.mlp: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ed010d82bf47398c289d1c9bb70b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Explanation:'), Button(description='Submit', style=ButtonStyle()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 84\u001b[0m, in \u001b[0;36mplot_examples\u001b[0;34m(layer_name, latent_number)\u001b[0m\n\u001b[1;32m     82\u001b[0m save_button\u001b[38;5;241m.\u001b[39mon_click(on_save)\n\u001b[1;32m     83\u001b[0m display(widgets\u001b[38;5;241m.\u001b[39mHBox([text_box, submit_button, skip_button, save_button]))\n\u001b[0;32m---> 84\u001b[0m \u001b[43mdisplay_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 45\u001b[0m, in \u001b[0;36mplot_examples.<locals>.display_example\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_example\u001b[39m(index):\n\u001b[0;32m---> 45\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[1;32m     47\u001b[0m     list_tokens \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plot_examples(\"1\",11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
